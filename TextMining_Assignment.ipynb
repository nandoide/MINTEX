{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules importation and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import TruncatedSVD# SVD = Singular Value Descomposition\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabaz_score, accuracy_score\n",
    "from sklearn.preprocessing import Normalizer, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accession number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29606186</td>\n",
       "      <td>Can reactivity and regulation in infancy predi...</td>\n",
       "      <td>A need to identify early infant markers of lat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29471205</td>\n",
       "      <td>Fabrication of bioinspired, self-cleaning supe...</td>\n",
       "      <td>The mechanical properties, corrosion-resistanc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29175165</td>\n",
       "      <td>Functional properties of chickpea protein isol...</td>\n",
       "      <td>In the present study, the effect of Refractanc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29098524</td>\n",
       "      <td>Mechanical dyssynchrony alters left ventricula...</td>\n",
       "      <td>The impact of left bundle branch block (LBBB) ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27507285</td>\n",
       "      <td>Reducing the width of confidence intervals for...</td>\n",
       "      <td>In the last decade, it has been shown that an ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accession number                                              Title  \\\n",
       "0          29606186  Can reactivity and regulation in infancy predi...   \n",
       "1          29471205  Fabrication of bioinspired, self-cleaning supe...   \n",
       "2          29175165  Functional properties of chickpea protein isol...   \n",
       "3          29098524  Mechanical dyssynchrony alters left ventricula...   \n",
       "4          27507285  Reducing the width of confidence intervals for...   \n",
       "\n",
       "                                            Abstract Label  \n",
       "0  A need to identify early infant markers of lat...     0  \n",
       "1  The mechanical properties, corrosion-resistanc...     0  \n",
       "2  In the present study, the effect of Refractanc...     0  \n",
       "3  The impact of left bundle branch block (LBBB) ...     0  \n",
       "4  In the last decade, it has been shown that an ...     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accession number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27829177</td>\n",
       "      <td>A naturally occurring variant of HPV-16 E7 exe...</td>\n",
       "      <td>Human Papillomavirus E6 and E7 play critical r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27806271</td>\n",
       "      <td>Functional Analysis of Orai1 Concatemers Suppo...</td>\n",
       "      <td>Store-operated Ca(2+) entry occurs through the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27796307</td>\n",
       "      <td>KAT2A/KAT2B-targeted acetylome reveals a role ...</td>\n",
       "      <td>Lysine acetylation is a widespread post-transl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27795438</td>\n",
       "      <td>The Cellular DNA Helicase ChlR1 Regulates Chro...</td>\n",
       "      <td>In papillomavirus infections, the viral genome...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27794539</td>\n",
       "      <td>Human R1441C LRRK2 regulates the synaptic vesi...</td>\n",
       "      <td>Mutations in leucine-rich repeat kinase 2 (LRR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accession number                                              Title  \\\n",
       "0          27829177  A naturally occurring variant of HPV-16 E7 exe...   \n",
       "1          27806271  Functional Analysis of Orai1 Concatemers Suppo...   \n",
       "2          27796307  KAT2A/KAT2B-targeted acetylome reveals a role ...   \n",
       "3          27795438  The Cellular DNA Helicase ChlR1 Regulates Chro...   \n",
       "4          27794539  Human R1441C LRRK2 regulates the synaptic vesi...   \n",
       "\n",
       "                                            Abstract Label  \n",
       "0  Human Papillomavirus E6 and E7 play critical r...     1  \n",
       "1  Store-operated Ca(2+) entry occurs through the...     1  \n",
       "2  Lysine acetylation is a widespread post-transl...     1  \n",
       "3  In papillomavirus infections, the viral genome...     1  \n",
       "4  Mutations in leucine-rich repeat kinase 2 (LRR...     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accession number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29606186</td>\n",
       "      <td>Can reactivity and regulation in infancy predi...</td>\n",
       "      <td>A need to identify early infant markers of lat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29471205</td>\n",
       "      <td>Fabrication of bioinspired, self-cleaning supe...</td>\n",
       "      <td>The mechanical properties, corrosion-resistanc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29175165</td>\n",
       "      <td>Functional properties of chickpea protein isol...</td>\n",
       "      <td>In the present study, the effect of Refractanc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29098524</td>\n",
       "      <td>Mechanical dyssynchrony alters left ventricula...</td>\n",
       "      <td>The impact of left bundle branch block (LBBB) ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27507285</td>\n",
       "      <td>Reducing the width of confidence intervals for...</td>\n",
       "      <td>In the last decade, it has been shown that an ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accession number                                              Title  \\\n",
       "0          29606186  Can reactivity and regulation in infancy predi...   \n",
       "1          29471205  Fabrication of bioinspired, self-cleaning supe...   \n",
       "2          29175165  Functional properties of chickpea protein isol...   \n",
       "3          29098524  Mechanical dyssynchrony alters left ventricula...   \n",
       "4          27507285  Reducing the width of confidence intervals for...   \n",
       "\n",
       "                                            Abstract Label  \n",
       "0  A need to identify early infant markers of lat...     0  \n",
       "1  The mechanical properties, corrosion-resistanc...     0  \n",
       "2  In the present study, the effect of Refractanc...     0  \n",
       "3  The impact of left bundle branch block (LBBB) ...     0  \n",
       "4  In the last decade, it has been shown that an ...     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8156 8156\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "NROWS = sys.maxsize\n",
    "#NROWS = 100\n",
    "## Negative dataset\n",
    "df_neg = pd.read_csv('./practica_clase/PRECISION_MEDICINE/negative_training_abstracts.tsv', sep='\\t', \n",
    "                     header=None, nrows = NROWS)\n",
    "\n",
    "df_neg.columns = ['Accession number', 'Title', 'Abstract']\n",
    "df_neg['Label'] = '0' #'neg'\n",
    "\n",
    "display(df_neg.head())\n",
    "\n",
    "corpus_neg = list(df_neg['Abstract'].values)\n",
    "### len(corpus_neg) # 4078\n",
    "\n",
    "## Positive\n",
    "df_pos = pd.read_csv('./practica_clase/PRECISION_MEDICINE/positive_training_abstracts.tsv', sep='\\t', \n",
    "                     header=None, nrows = NROWS)\n",
    "\n",
    "df_pos.columns = ['Accession number', 'Title', 'Abstract']\n",
    "df_pos['Label'] = '1' # 'pos'\n",
    "display(df_pos.head())\n",
    "\n",
    "# Add corpus\n",
    "df_corpus = df_neg.append(df_pos)\n",
    "display(df_corpus.head())\n",
    "\n",
    "# len(corpus) # 8156\n",
    "\n",
    "labels = df_corpus['Label']\n",
    "corpus = df_corpus['Abstract']\n",
    "# len(labels) # 8156\n",
    "\n",
    "print(len(corpus), len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    corpus, labels, test_size=TEST_SIZE, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. Construction of an automatic classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters can be adjusted in order to try to maximize the quality of the\n",
    "classifier:\n",
    "\n",
    "- In function TfidfVectorizer:\n",
    "    * Parameters that affect the vocabulary quality:\n",
    "        * List of stopwords (one of the options is setting it to None)\n",
    "        * maxfeatures\n",
    "        * max_df, min_df\n",
    "    * Norm (none, ‘l1’ or ‘l2’)\n",
    "    \n",
    "- In Latent Semantic Analysis (LSA):\n",
    "    * n_components\n",
    "    * not performing LSA\n",
    "    \n",
    "- Classifier model:\n",
    "    * You can use strategies included in some of the notebooks we used \n",
    "        * Logistic Regression, \n",
    "        * Naïve Bayes, \n",
    "        * decision trees, \n",
    "        * SVC\n",
    "        * or others you learnt from the Machine Learning course (k-nn, neural networks, etc.)\n",
    "\n",
    "The goal is not to check all possible combinations of these parameters but respond to thesequestions:\n",
    "\n",
    "- Which tips can you give about constructing an automatic text classifier? What do you recommend to do? What do you recommend not to do?\n",
    "- What is the best classifier you have obtained?\n",
    "\n",
    "Your responses to these questions should be illustrated with tables and/or figures and/or\n",
    "screen captures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy: Hyper-Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para abordar este proyecto hemos decidido utilizar la versatilidad de los objetos *pipeline* del paquete *sklearn*, rodeándolo con un conjunto de métodos propios para dotarle si cabe de aún mayor dinamismo.\n",
    "\n",
    "Esta estrategia finalmente nos ha llevado a desarrollar una utilidad de ajuste de parámetros que hemos bautizado como **Hyper-Grid Search** o abreviadamente **HG**. Aunque está muy relacionada con la necesidad que emana del proyecto actual de explorar la precisión de un conjunto de reducers combinados con un conjunto de classifiers, podría generalizarse a cualquier escenario de exploración. Incluso lo visualizamos como una herramienta muy útil para ajustar un ensemble de reducers-classifiers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Find additional stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \"\"\"\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return words_freq[:n]\n",
    "\n",
    "def improve_stop_words(X_train, n=50):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    common_words = [i[0] for i in get_top_n_words(X_train, n)]\n",
    "    eng_and_custom_stopwords = set(list(stop_words.ENGLISH_STOP_WORDS) + common_words)\n",
    "    print(\"Stop words count:\", len(eng_and_custom_stopwords))\n",
    "    return eng_and_custom_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelining methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "CLASSIFIERS = ['knn', 'dtree', 'nb', 'lr', 'svc', 'lsvc']\n",
    "CLASSIFIERS_UNSUPERVISED = ['kmeans']\n",
    "REDUCERS = ['svd', 'kbest', 'percentile', 'none']\n",
    "CV = 4\n",
    "VERBOSE = False\n",
    "\n",
    "def create_text_pipeline(reducer='svd', classifier=\"nb\"):\n",
    "    \"\"\" Create text vectorization pipeline with optional dimensionality reduction\"\"\"\n",
    "    assert reducer in REDUCERS, \"ERROR: Reducer %s not supported, only %s\" % (reducer, REDUCERS)\n",
    "    assert classifier in CLASSIFIERS + CLASSIFIERS_UNSUPERVISED,\\\n",
    "        \"ERROR: Classifier %s not supported, only %s\" % (classifier, CLASSIFIERS + CLASSIFIERS_UNSUPERVISED)\n",
    "    pipeline = [\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    "    # Reduce dimensions\n",
    "    if reducer == 'svd':\n",
    "        pipeline.append(('red_svd', TruncatedSVD()))\n",
    "    elif reducer == 'kbest':\n",
    "        pipeline.append(('red_kbest', SelectKBest()))\n",
    "    elif reducer == 'percentile':\n",
    "        pipeline.append(('red_percentile', SelectPercentile()))\n",
    "    elif reducer == 'none':\n",
    "        pass\n",
    "    \n",
    "    # Classify\n",
    "    if classifier == \"nb\":\n",
    "        if reducer == 'svd':\n",
    "            pipeline.append(('clf_nb_scaler', MinMaxScaler()))\n",
    "        elif reducer == 'kbest':\n",
    "            pipeline.append(('clf_nb_scaler', MaxAbsScaler()))\n",
    "        elif reducer == 'percentile':\n",
    "            pipeline.append(('clf_nb_scaler', MaxAbsScaler()))\n",
    "        elif reducer == 'none':\n",
    "            pass\n",
    "        pipeline.append(('clf_' + classifier, MultinomialNB()))\n",
    "    elif classifier == \"lr\":\n",
    "        pipeline.append(('clf_' + classifier, LogisticRegression()))\n",
    "    elif classifier == \"svc\":\n",
    "        pipeline.append(('clf_' + classifier, SVC()))\n",
    "    elif classifier == \"lsvc\":\n",
    "        pipeline.append(('clf_' + classifier, LinearSVC()))\n",
    "    elif classifier == \"dtree\":\n",
    "        pipeline.append(('clf_' + classifier, DecisionTreeClassifier())) \n",
    "    elif classifier == \"knn\":\n",
    "        pipeline.append(('clf_' + classifier, KNeighborsClassifier()))    \n",
    "    elif classifier == \"kmeans\":\n",
    "        pipeline.append(('clf_kmeans_norm', Normalizer()))\n",
    "        pipeline.append(('clf_kmeans', KMeans()))\n",
    "    elif classifier == 'none':\n",
    "        pass\n",
    "    \n",
    "    return Pipeline(pipeline)\n",
    "\n",
    "def get_prediction_from_cluster(X, pipeline):\n",
    "    \"\"\" Transform cluster assignment in y_pred object\"\"\"\n",
    "    def swap_label(label):\n",
    "        if label == 1:\n",
    "            return '0'\n",
    "        elif label == 0:\n",
    "            return '1'\n",
    "        else:\n",
    "            return str(label)\n",
    "    labels = pipeline.predict(X_test)\n",
    "    labels_predicted = [str(label) for label in labels]\n",
    "    predicted = pd.Series(labels_predicted)\n",
    "    accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "    labels_predicted_reverse = [swap_label(label) for label in labels]\n",
    "    predicted_reverse = pd.Series(labels_predicted_reverse)\n",
    "    accuracy_reverse = metrics.accuracy_score(y_test, predicted_reverse)\n",
    "    if accuracy_reverse > accuracy: predicted = predicted_reverse\n",
    "    return predicted\n",
    "\n",
    "def get_filtered_params(parameters, pipeline):\n",
    "    \"\"\" Filter the params that aren't related to steps in the pipeline \"\"\"\n",
    "    filtered_params = {}\n",
    "    for param_key in parameters.keys():\n",
    "        if param_key.split('__')[0] in pipeline.named_steps.keys():\n",
    "            filtered_params[param_key] = parameters[param_key]\n",
    "    return filtered_params\n",
    "\n",
    "def params2search(parameters_search, parameters_prev):\n",
    "    \"\"\" Convert params to search params \"\"\"\n",
    "    # Generalize params to list of params\n",
    "    if type(parameters_search) == dict:\n",
    "        parameters = [parameters_search]\n",
    "    else:\n",
    "        parameters = parameters_search\n",
    "    search_params_set = []\n",
    "    for param_set in parameters:\n",
    "        search_params = param_set.copy()\n",
    "        for param_key in parameters_prev.keys():\n",
    "            if param_key not in param_set:\n",
    "                search_params[param_key] = [parameters_prev[param_key]]\n",
    "        search_params_set.append(search_params)\n",
    "    return search_params_set\n",
    "\n",
    "def get_filtered_set(parameters, pipeline):\n",
    "    \"\"\" Filter the params that aren't related to steps in the pipeline \"\"\"\n",
    "    if type(parameters) == dict:\n",
    "        return get_filtered_params(parameters, pipeline)\n",
    "    else:\n",
    "        filtered_set = []\n",
    "        for param_set in parameters:\n",
    "            filtered_set.append(get_filtered_params(param_set, pipeline))\n",
    "        return filtered_set\n",
    "    \n",
    "def prediction_metrics(X_train, y_train, X_test, y_test, parameters, results, reducer=\"svd\", classifier=\"nb\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print(\"### Reducer: %s   Classifier: %s\" %(reducer, classifier))\n",
    "    pipeline = create_text_pipeline(reducer=reducer, classifier=classifier)\n",
    "    pipeline.set_params(**get_filtered_params(parameters, pipeline))\n",
    "    if VERBOSE: print(\"Pipeline\", pipeline.named_steps)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    if classifier in CLASSIFIERS_UNSUPERVISED:\n",
    "        predicted = get_prediction_from_cluster(X_test, pipeline)\n",
    "    else:\n",
    "        predicted = pipeline.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "    print(\"Accuracy\", accuracy)\n",
    "    clf_rep = metrics.classification_report(y_test, predicted, output_dict=True, digits=2)\n",
    "    if VERBOSE: print(clf_rep['micro avg'])\n",
    "    if VERBOSE: print(metrics.confusion_matrix(y_test, predicted))\n",
    "    print()\n",
    "    \n",
    "    results.append([reducer, classifier] + list(clf_rep['micro avg'].values()) + [parameters])\n",
    "    \n",
    "def process_classifications(X_train, y_train, X_test, y_test, parameters,\n",
    "                            classifiers=CLASSIFIERS, reducers=REDUCERS):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for classifier in classifiers:\n",
    "        for reducer in reducers:\n",
    "            prediction_metrics(X_train, y_train, X_test, y_test, parameters, results, reducer, classifier)\n",
    "    # Group all results into a dataframe\n",
    "    df = pd.DataFrame(results, columns=['reducer', 'classifier', 'precision', 'recall', 'f1-score', 'support', 'params'])\n",
    "    df['classifier'].fillna('None',inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prediction_metrics_grid(X_train, y_train, X_test, y_test, parameters_grid, results=[], \n",
    "                            reducer=\"svd\", classifier=\"nb\", cv=CV):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print(\"### Reducer: %s   Classifier: %s\" %(reducer, classifier))\n",
    "    pipeline = create_text_pipeline(reducer=reducer, classifier=classifier)\n",
    "    filtered_params = get_filtered_set(parameters_grid, pipeline)\n",
    "    #scoring = {'accuracy': make_scorer(accuracy_score), 'calinski': make_scorer(calinski_harabaz_score)}\n",
    "    scoring = {'accuracy': make_scorer(accuracy_score)}\n",
    "    grid_model = GridSearchCV(pipeline, filtered_params, cv=cv, iid=False, error_score=0,\n",
    "                              scoring=None, refit=False)\n",
    "    grid_model.fit(X_train, y_train)\n",
    "    print()\n",
    "    print(\"Best parameters\")\n",
    "    for param_name in sorted(grid_model.best_params_.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, grid_model.best_params_[param_name]))  \n",
    "    pipeline.set_params(**grid_model.best_params_)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    if classifier in CLASSIFIERS_UNSUPERVISED:\n",
    "        predicted = get_prediction_from_cluster(X_test, pipeline)\n",
    "    else:\n",
    "        predicted = pipeline.predict(X_test)\n",
    "    print()\n",
    "    accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "    print(\"Accuracy\", accuracy)\n",
    "    clf_rep = metrics.classification_report(y_test, predicted, output_dict=True, digits=2)\n",
    "    if VERBOSE: print(clf_rep['micro avg'])\n",
    "    if VERBOSE: print(metrics.confusion_matrix(y_test, predicted))\n",
    "    print()\n",
    "    \n",
    "    results.append([reducer, classifier] + list(clf_rep['micro avg'].values()) + [grid_model.best_params_])\n",
    "\n",
    "    \n",
    "def process_classifications_grid(X_train, y_train, X_test, y_test, parameters, cv=CV,\n",
    "                            classifiers=CLASSIFIERS, reducers=REDUCERS):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for classifier in classifiers:\n",
    "        for reducer in reducers:\n",
    "            prediction_metrics_grid(X_train, y_train, X_test, y_test, parameters, \n",
    "                                        results, reducer, classifier, cv=cv)\n",
    "    # Group all results into a dataframe\n",
    "    df = pd.DataFrame(results, columns=['reducer', 'classifier', 'precision', 'recall', 'f1-score', 'support', 'params'])\n",
    "    df['classifier'].fillna('None',inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Grid methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params2search(parameters_search, parameters_prev):\n",
    "    \"\"\" Convert params to search params \"\"\"\n",
    "    # Generalize params to list of params\n",
    "    if type(parameters_search) == dict:\n",
    "        parameters = [parameters_search]\n",
    "    else:\n",
    "        parameters = parameters_search\n",
    "    search_params_set = []\n",
    "    for param_set in parameters:\n",
    "        #print(param_set['vect__min_df'])\n",
    "        search_params = param_set.copy()\n",
    "        for param_key in parameters_prev.keys():\n",
    "            if param_key not in param_set.keys():\n",
    "                #print(\"Key:\", param_key)\n",
    "                search_params[param_key] = [parameters_prev[param_key]]\n",
    "        search_params_set.append(search_params)\n",
    "    return search_params_set\n",
    "\n",
    "def hyper_grid_search(grids_parameters, df_metrics_old, reducers, classifiers):\n",
    "    \"\"\"\n",
    "    Main method for search\n",
    "    \"\"\"\n",
    "    for step, grid_parameters in enumerate(grids_parameters):\n",
    "        #df_metrics_new = df_metrics_old[~(df_metrics_old['reducer'].isin(reducers)) & ~(df_metrics_old['classifier'].isin(classifiers))]\n",
    "        df_metrics_new = pd.DataFrame()\n",
    "        df_metrics_old_cp = df_metrics_old.copy()\n",
    "        reducers_affected, classifiers_affected = params2affected(grid_parameters)\n",
    "        for reducer in reducers:\n",
    "            for classifier in classifiers:\n",
    "                print(\"Step\", step, \"Reducer\", reducer, \"Classifier\", classifier)\n",
    "                if reducer in reducers_affected and classifier in classifiers_affected:\n",
    "                    params = list(df_metrics_old[(df_metrics_old['reducer'] == reducer)\\\n",
    "                                                 & (df_metrics_old['classifier'] == classifier)]['params'])[0]\n",
    "                    new_search_params = params2search(grid_parameters, params)\n",
    "                    #print(\"New parameters\",new_search_params)\n",
    "                    df_metrics_tmp = process_classifications_grid(X_train, y_train, X_test, y_test, new_search_params, \n",
    "                                             reducers=[reducer], classifiers=[classifier])\n",
    "                    df_metrics_new = df_metrics_new.append(df_metrics_tmp)\n",
    "                else:\n",
    "                    print('not affected')\n",
    "                    df_metrics_new = df_metrics_new.append(df_metrics_old_cp[(df_metrics_old_cp['reducer'] == reducer)\\\n",
    "                                                 & (df_metrics_old_cp['classifier'] == classifier)])\n",
    "        df_metrics_new = df_metrics_new.append(df_metrics_old_cp[~(df_metrics_old_cp['reducer'].isin(reducers) & df_metrics_old_cp['classifier'].isin(classifiers))])\n",
    "        df_metrics_old = df_metrics_new\n",
    "    \n",
    "    return df_metrics_new            \n",
    "\n",
    "def params2affected(parameters_search):\n",
    "    \"\"\" Decide if affected \"\"\"\n",
    "    # Generalize params to list of params\n",
    "    if type(parameters_search) == dict:\n",
    "        parameters = [parameters_search]\n",
    "    else:\n",
    "        parameters = parameters_search\n",
    "    reducers = []\n",
    "    classifiers = []\n",
    "    all_reducers = False\n",
    "    all_classifiers = False\n",
    "    for param_set in parameters:\n",
    "        for param_key in param_set.keys():\n",
    "            key = param_key.split('__')[0]\n",
    "            t = key.split('_')[0]\n",
    "            if t == 'red':\n",
    "                reducers.append(key.split('_')[1])\n",
    "                all_classifiers = True\n",
    "            elif t == 'clf':\n",
    "                classifiers.append(key.split('_')[1])\n",
    "                all_reducers = True\n",
    "            elif t == 'vect': #all reducers and classifiers affected\n",
    "                all_classifiers = True\n",
    "                all_reducers = True\n",
    "    if all_reducers: reducers = REDUCERS\n",
    "    if all_classifiers: classifiers = CLASSIFIERS + CLASSIFIERS_UNSUPERVISED\n",
    "    return reducers, classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main process with prefixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words count: 449\n",
      "### Reducer: svd   Classifier: knn\n",
      "Accuracy 0.9654531946508172\n",
      "\n",
      "### Reducer: kbest   Classifier: knn\n",
      "Accuracy 0.8766716196136701\n",
      "\n",
      "### Reducer: percentile   Classifier: knn\n",
      "Accuracy 0.8543833580980683\n",
      "\n",
      "### Reducer: none   Classifier: knn\n",
      "Accuracy 0.5100297176820208\n",
      "\n",
      "### Reducer: svd   Classifier: dtree\n",
      "Accuracy 0.9483655274888558\n",
      "\n",
      "### Reducer: kbest   Classifier: dtree\n",
      "Accuracy 0.861812778603269\n",
      "\n",
      "### Reducer: percentile   Classifier: dtree\n",
      "Accuracy 0.9201337295690936\n",
      "\n",
      "### Reducer: none   Classifier: dtree\n",
      "Accuracy 0.9182763744427934\n",
      "\n",
      "### Reducer: svd   Classifier: nb\n",
      "Accuracy 0.9647102526002972\n",
      "\n",
      "### Reducer: kbest   Classifier: nb\n",
      "Accuracy 0.34583952451708766\n",
      "\n",
      "### Reducer: percentile   Classifier: nb\n",
      "Accuracy 0.9309063893016345\n",
      "\n",
      "### Reducer: none   Classifier: nb\n",
      "Accuracy 0.9565378900445766\n",
      "\n",
      "### Reducer: svd   Classifier: lr\n",
      "Accuracy 0.9702823179791976\n",
      "\n",
      "### Reducer: kbest   Classifier: lr\n",
      "Accuracy 0.8610698365527489\n",
      "\n",
      "### Reducer: percentile   Classifier: lr\n",
      "Accuracy 0.9598811292719168\n",
      "\n",
      "### Reducer: none   Classifier: lr\n",
      "Accuracy 0.975111441307578\n",
      "\n",
      "### Reducer: svd   Classifier: svc\n",
      "Accuracy 0.9691679049034175\n",
      "\n",
      "### Reducer: kbest   Classifier: svc\n",
      "Accuracy 0.8610698365527489\n",
      "\n",
      "### Reducer: percentile   Classifier: svc\n",
      "Accuracy 0.9528231797919762\n",
      "\n",
      "### Reducer: none   Classifier: svc\n",
      "Accuracy 0.49925705794947994\n",
      "\n",
      "### Reducer: svd   Classifier: lsvc\n",
      "Accuracy 0.9706537890044576\n",
      "\n",
      "### Reducer: kbest   Classifier: lsvc\n",
      "Accuracy 0.8681277860326895\n",
      "\n",
      "### Reducer: percentile   Classifier: lsvc\n",
      "Accuracy 0.9591381872213968\n",
      "\n",
      "### Reducer: none   Classifier: lsvc\n",
      "Accuracy 0.9706537890044576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = False\n",
    "# More stop words\n",
    "eng_and_custom_stopwords = improve_stop_words(X_train, 200)\n",
    "reducers=REDUCERS\n",
    "classifiers = CLASSIFIERS\n",
    "\n",
    "# First set of parameters\n",
    "param_ini = { \n",
    "    'vect__norm': None,\n",
    "    'vect__smooth_idf': True,\n",
    "    'vect__sublinear_tf': True,\n",
    "    'vect__max_features': 1000,\n",
    "    'vect__min_df': 1,\n",
    "    'vect__max_df': 1.,\n",
    "    'vect__stop_words': 'english',\n",
    "    'vect__strip_accents' : 'unicode',\n",
    "    'vect__analyzer' : 'word',\n",
    "    #'vect__token_pattern': r'\\w{1,}', \n",
    "    'vect__ngram_range' : (1, 2),\n",
    "    'scaler' : None,\n",
    "    'red_kbest__k' : 5,\n",
    "    'red_percentile__score_func' : f_classif,\n",
    "    'red_percentile__percentile' : 10,\n",
    "    'vect__norm': 'l2',\n",
    "    'red_svd__n_components': 10,\n",
    "    'clf_knn__n_neighbors' : 8,\n",
    "}\n",
    "\n",
    "df_metrics_fixed = process_classifications(X_train, y_train, X_test, y_test, param_ini, \n",
    "                             reducers=reducers, classifiers=classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reducer</th>\n",
       "      <th>classifier</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.965453</td>\n",
       "      <td>0.965453</td>\n",
       "      <td>0.965453</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kbest</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.876672</td>\n",
       "      <td>0.876672</td>\n",
       "      <td>0.876672</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>percentile</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.854383</td>\n",
       "      <td>0.854383</td>\n",
       "      <td>0.854383</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.510030</td>\n",
       "      <td>0.510030</td>\n",
       "      <td>0.510030</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svd</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.948366</td>\n",
       "      <td>0.948366</td>\n",
       "      <td>0.948366</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kbest</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.861813</td>\n",
       "      <td>0.861813</td>\n",
       "      <td>0.861813</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>percentile</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.920134</td>\n",
       "      <td>0.920134</td>\n",
       "      <td>0.920134</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>none</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.918276</td>\n",
       "      <td>0.918276</td>\n",
       "      <td>0.918276</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svd</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.964710</td>\n",
       "      <td>0.964710</td>\n",
       "      <td>0.964710</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kbest</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.345840</td>\n",
       "      <td>0.345840</td>\n",
       "      <td>0.345840</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>percentile</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.930906</td>\n",
       "      <td>0.930906</td>\n",
       "      <td>0.930906</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>none</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.956538</td>\n",
       "      <td>0.956538</td>\n",
       "      <td>0.956538</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svd</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.970282</td>\n",
       "      <td>0.970282</td>\n",
       "      <td>0.970282</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kbest</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.861070</td>\n",
       "      <td>0.861070</td>\n",
       "      <td>0.861070</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>percentile</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.959881</td>\n",
       "      <td>0.959881</td>\n",
       "      <td>0.959881</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>none</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.975111</td>\n",
       "      <td>0.975111</td>\n",
       "      <td>0.975111</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>svd</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.969168</td>\n",
       "      <td>0.969168</td>\n",
       "      <td>0.969168</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kbest</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.861070</td>\n",
       "      <td>0.861070</td>\n",
       "      <td>0.861070</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>percentile</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.952823</td>\n",
       "      <td>0.952823</td>\n",
       "      <td>0.952823</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>none</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.499257</td>\n",
       "      <td>0.499257</td>\n",
       "      <td>0.499257</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>svd</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.970654</td>\n",
       "      <td>0.970654</td>\n",
       "      <td>0.970654</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kbest</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.868128</td>\n",
       "      <td>0.868128</td>\n",
       "      <td>0.868128</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>percentile</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.959138</td>\n",
       "      <td>0.959138</td>\n",
       "      <td>0.959138</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>none</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.970654</td>\n",
       "      <td>0.970654</td>\n",
       "      <td>0.970654</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': &lt;function f_classif at 0x1a1db441e0&gt;, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reducer classifier  precision    recall  f1-score  support  \\\n",
       "0   svd         knn        0.965453   0.965453  0.965453  2692      \n",
       "1   kbest       knn        0.876672   0.876672  0.876672  2692      \n",
       "2   percentile  knn        0.854383   0.854383  0.854383  2692      \n",
       "3   none        knn        0.510030   0.510030  0.510030  2692      \n",
       "4   svd         dtree      0.948366   0.948366  0.948366  2692      \n",
       "5   kbest       dtree      0.861813   0.861813  0.861813  2692      \n",
       "6   percentile  dtree      0.920134   0.920134  0.920134  2692      \n",
       "7   none        dtree      0.918276   0.918276  0.918276  2692      \n",
       "8   svd         nb         0.964710   0.964710  0.964710  2692      \n",
       "9   kbest       nb         0.345840   0.345840  0.345840  2692      \n",
       "10  percentile  nb         0.930906   0.930906  0.930906  2692      \n",
       "11  none        nb         0.956538   0.956538  0.956538  2692      \n",
       "12  svd         lr         0.970282   0.970282  0.970282  2692      \n",
       "13  kbest       lr         0.861070   0.861070  0.861070  2692      \n",
       "14  percentile  lr         0.959881   0.959881  0.959881  2692      \n",
       "15  none        lr         0.975111   0.975111  0.975111  2692      \n",
       "16  svd         svc        0.969168   0.969168  0.969168  2692      \n",
       "17  kbest       svc        0.861070   0.861070  0.861070  2692      \n",
       "18  percentile  svc        0.952823   0.952823  0.952823  2692      \n",
       "19  none        svc        0.499257   0.499257  0.499257  2692      \n",
       "20  svd         lsvc       0.970654   0.970654  0.970654  2692      \n",
       "21  kbest       lsvc       0.868128   0.868128  0.868128  2692      \n",
       "22  percentile  lsvc       0.959138   0.959138  0.959138  2692      \n",
       "23  none        lsvc       0.970654   0.970654  0.970654  2692      \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                     params  \n",
       "0   {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "1   {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "2   {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "3   {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "4   {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "5   {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "6   {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "7   {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "8   {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "9   {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "10  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "11  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "12  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "13  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "14  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "15  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "16  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "17  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "18  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "19  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "20  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "21  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "22  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  \n",
       "23  {'vect__norm': 'l2', 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__max_features': 1000, 'vect__min_df': 1, 'vect__max_df': 1.0, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__analyzer': 'word', 'vect__ngram_range': (1, 2), 'scaler': None, 'red_kbest__k': 5, 'red_percentile__score_func': <function f_classif at 0x1a1db441e0>, 'red_percentile__percentile': 10, 'red_svd__n_components': 10, 'clf_knn__n_neighbors': 8}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(df_metrics_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main process with grid search parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for enrichment with vectorizer grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 Reducer svd Classifier lsvc\n",
      "### Reducer: svd   Classifier: lsvc\n",
      "\n",
      "Best parameters\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9696969696969697\n",
      "\n",
      "Step 0 Reducer svd Classifier knn\n",
      "### Reducer: svd   Classifier: knn\n",
      "\n",
      "Best parameters\n",
      "\tclf_knn__n_neighbors: 8\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9696969696969697\n",
      "\n",
      "Step 0 Reducer svd Classifier lr\n",
      "### Reducer: svd   Classifier: lr\n",
      "\n",
      "Best parameters\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9696969696969697\n",
      "\n",
      "Step 0 Reducer kbest Classifier lsvc\n",
      "### Reducer: kbest   Classifier: lsvc\n",
      "\n",
      "Best parameters\n",
      "\tred_kbest__k: 3\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.8181818181818182\n",
      "\n",
      "Step 0 Reducer kbest Classifier knn\n",
      "### Reducer: kbest   Classifier: knn\n",
      "\n",
      "Best parameters\n",
      "\tclf_knn__n_neighbors: 8\n",
      "\tred_kbest__k: 3\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: 'english'\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9393939393939394\n",
      "\n",
      "Step 0 Reducer kbest Classifier lr\n",
      "### Reducer: kbest   Classifier: lr\n",
      "\n",
      "Best parameters\n",
      "\tred_kbest__k: 3\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.2\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: 'english'\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.8484848484848485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First we adjust the vectorizer parameters\n",
    "param_grid_vectorizer = { \n",
    "    'vect__norm': ['l1', 'l2', None],\n",
    "    'vect__max_features': [500, 1000],\n",
    "    'vect__min_df': [1, 0.1, 0.2],\n",
    "    'vect__max_df': [0.1, 0.2, 0.5, 1.],\n",
    "    'vect__stop_words': [None, 'english', eng_and_custom_stopwords]\n",
    "}\n",
    "\n",
    "classifiers=['lsvc','knn', 'lr']\n",
    "\n",
    "df_metrics_new = hyper_grid_search([param_grid_vectorizer], df_metrics_fixed, reducers=reducers, classifiers=classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reducer</th>\n",
       "      <th>classifier</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>33</td>\n",
       "      <td>{'red_svd__n_components': 10, 'scaler': None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>33</td>\n",
       "      <td>{'clf_knn__n_neighbors': 8, 'red_svd__n_compon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>33</td>\n",
       "      <td>{'red_svd__n_components': 10, 'scaler': None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kbest</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>33</td>\n",
       "      <td>{'red_kbest__k': 3, 'scaler': None, 'vect__ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kbest</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'clf_knn__n_neighbors': 8, 'red_kbest__k': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kbest</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>33</td>\n",
       "      <td>{'red_kbest__k': 3, 'scaler': None, 'vect__ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svd</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kbest</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svd</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kbest</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svd</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kbest</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reducer classifier  precision    recall  f1-score  support  \\\n",
       "0     svd       lsvc   0.969697  0.969697  0.969697       33   \n",
       "0     svd        knn   0.969697  0.969697  0.969697       33   \n",
       "0     svd         lr   0.969697  0.969697  0.969697       33   \n",
       "0   kbest       lsvc   0.818182  0.818182  0.818182       33   \n",
       "0   kbest        knn   0.939394  0.939394  0.939394       33   \n",
       "0   kbest         lr   0.848485  0.848485  0.848485       33   \n",
       "2     svd      dtree   0.939394  0.939394  0.939394       33   \n",
       "3   kbest      dtree   0.878788  0.878788  0.878788       33   \n",
       "4     svd         nb   0.909091  0.909091  0.909091       33   \n",
       "5   kbest         nb   0.575758  0.575758  0.575758       33   \n",
       "8     svd        svc   0.454545  0.454545  0.454545       33   \n",
       "9   kbest        svc   0.454545  0.454545  0.454545       33   \n",
       "\n",
       "                                              params  \n",
       "0  {'red_svd__n_components': 10, 'scaler': None, ...  \n",
       "0  {'clf_knn__n_neighbors': 8, 'red_svd__n_compon...  \n",
       "0  {'red_svd__n_components': 10, 'scaler': None, ...  \n",
       "0  {'red_kbest__k': 3, 'scaler': None, 'vect__ana...  \n",
       "0  {'clf_knn__n_neighbors': 8, 'red_kbest__k': 3,...  \n",
       "0  {'red_kbest__k': 3, 'scaler': None, 'vect__ana...  \n",
       "2  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "3  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "4  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "5  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "8  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "9  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_metrics_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for enrichment from reducer grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 Reducer svd Classifier lsvc\n",
      "### Reducer: svd   Classifier: lsvc\n",
      "\n",
      "Best parameters\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9696969696969697\n",
      "\n",
      "Step 0 Reducer svd Classifier knn\n",
      "### Reducer: svd   Classifier: knn\n",
      "\n",
      "Best parameters\n",
      "\tclf_knn__n_neighbors: 8\n",
      "\tred_svd__n_components: 3\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9090909090909091\n",
      "\n",
      "Step 0 Reducer svd Classifier lr\n",
      "### Reducer: svd   Classifier: lr\n",
      "\n",
      "Best parameters\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9696969696969697\n",
      "\n",
      "Step 0 Reducer kbest Classifier lsvc\n",
      "### Reducer: kbest   Classifier: lsvc\n",
      "\n",
      "Best parameters\n",
      "\tred_kbest__k: 20\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.8787878787878788\n",
      "\n",
      "Step 0 Reducer kbest Classifier knn\n",
      "### Reducer: kbest   Classifier: knn\n",
      "\n",
      "Best parameters\n",
      "\tclf_knn__n_neighbors: 8\n",
      "\tred_kbest__k: 3\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: 'english'\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9393939393939394\n",
      "\n",
      "Step 0 Reducer kbest Classifier lr\n",
      "### Reducer: kbest   Classifier: lr\n",
      "\n",
      "Best parameters\n",
      "\tred_kbest__k: 3\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.2\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: 'english'\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.8484848484848485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_reducers = [\n",
    "    {\n",
    "         'red_svd__n_components' : [2, 3, 10, 30, 40, 100],\n",
    "         'red_kbest__k' : [1, 2, 3, 5, 10, 20, 50, 60],\n",
    "         'red_percentile__score_func' : [f_classif],\n",
    "         'red_percentile__percentile' : [5, 10]\n",
    "    }\n",
    "]\n",
    "\n",
    "df_metrics_reducers = hyper_grid_search([param_grid_reducers], df_metrics_new, reducers=reducers, classifiers=classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reducer</th>\n",
       "      <th>classifier</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'red_svd__n_components': 40, 'scaler': None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'clf_knn__n_neighbors': 8, 'red_svd__n_compon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kbest</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>33</td>\n",
       "      <td>{'red_kbest__k': 20, 'scaler': None, 'vect__an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kbest</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'clf_knn__n_neighbors': 8, 'red_kbest__k': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svd</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kbest</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svd</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kbest</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svd</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kbest</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svd</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kbest</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reducer classifier  precision    recall  f1-score  support  \\\n",
       "0     svd       lsvc   0.939394  0.939394  0.939394       33   \n",
       "0     svd        knn   0.939394  0.939394  0.939394       33   \n",
       "0   kbest       lsvc   0.878788  0.878788  0.878788       33   \n",
       "0   kbest        knn   0.939394  0.939394  0.939394       33   \n",
       "2     svd      dtree   0.939394  0.939394  0.939394       33   \n",
       "3   kbest      dtree   0.878788  0.878788  0.878788       33   \n",
       "4     svd         nb   0.909091  0.909091  0.909091       33   \n",
       "5   kbest         nb   0.575758  0.575758  0.575758       33   \n",
       "6     svd         lr   0.939394  0.939394  0.939394       33   \n",
       "7   kbest         lr   0.696970  0.696970  0.696970       33   \n",
       "8     svd        svc   0.454545  0.454545  0.454545       33   \n",
       "9   kbest        svc   0.454545  0.454545  0.454545       33   \n",
       "\n",
       "                                              params  \n",
       "0  {'red_svd__n_components': 40, 'scaler': None, ...  \n",
       "0  {'clf_knn__n_neighbors': 8, 'red_svd__n_compon...  \n",
       "0  {'red_kbest__k': 20, 'scaler': None, 'vect__an...  \n",
       "0  {'clf_knn__n_neighbors': 8, 'red_kbest__k': 3,...  \n",
       "2  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "3  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "4  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "5  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "6  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "7  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "8  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "9  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_reducers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for enrichment for classifier grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 Reducer svd Classifier lsvc\n",
      "not affected\n",
      "Step 0 Reducer svd Classifier knn\n",
      "### Reducer: svd   Classifier: knn\n",
      "\n",
      "Best parameters\n",
      "\tclf_knn__n_neighbors: 10\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9696969696969697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters_classifiers = {\n",
    "    'clf_knn__n_neighbors' : [2, 5, 8, 10, 12, 20]\n",
    "}\n",
    "\n",
    "df_metrics_classif = hyper_grid_search([parameters_classifiers], df_metrics_reducers, \n",
    "                                       reducers=reducers, classifiers=classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reducer</th>\n",
       "      <th>classifier</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>33</td>\n",
       "      <td>{'red_svd__n_components': 10, 'scaler': None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>33</td>\n",
       "      <td>{'clf_knn__n_neighbors': 10, 'red_svd__n_compo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svd</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svd</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svd</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svd</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reducer classifier  precision    recall  f1-score  support  \\\n",
       "0     svd       lsvc   0.969697  0.969697  0.969697       33   \n",
       "0     svd        knn   0.969697  0.969697  0.969697       33   \n",
       "1     svd      dtree   0.909091  0.909091  0.909091       33   \n",
       "2     svd         nb   0.909091  0.909091  0.909091       33   \n",
       "3     svd         lr   0.939394  0.939394  0.939394       33   \n",
       "4     svd        svc   0.454545  0.454545  0.454545       33   \n",
       "\n",
       "                                              params  \n",
       "0  {'red_svd__n_components': 10, 'scaler': None, ...  \n",
       "0  {'clf_knn__n_neighbors': 10, 'red_svd__n_compo...  \n",
       "1  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "2  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "3  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "4  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_metrics_classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 Reducer svd Classifier knn\n",
      "### Reducer: svd   Classifier: knn\n",
      "\n",
      "Best parameters\n",
      "\tclf_knn__n_neighbors: 8\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 1000\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: None\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9665676077265973\n",
      "\n",
      "Step 0 Reducer svd Classifier dtree\n",
      "### Reducer: svd   Classifier: dtree\n",
      "\n",
      "Best parameters\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 1000\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.950965824665676\n",
      "\n",
      "Step 0 Reducer svd Classifier nb\n",
      "### Reducer: svd   Classifier: nb\n",
      "\n",
      "Best parameters\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 1000\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9639673105497771\n",
      "\n",
      "Step 0 Reducer svd Classifier lr\n",
      "### Reducer: svd   Classifier: lr\n",
      "\n",
      "Best parameters\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 1000\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: None\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9717682020802377\n",
      "\n",
      "Step 0 Reducer svd Classifier svc\n",
      "### Reducer: svd   Classifier: svc\n",
      "\n",
      "Best parameters\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 1000\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9695393759286776\n",
      "\n",
      "Step 0 Reducer svd Classifier lsvc\n",
      "### Reducer: svd   Classifier: lsvc\n",
      "\n",
      "Best parameters\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 1000\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9710252600297177\n",
      "\n",
      "Step 0 Reducer kbest Classifier knn\n",
      "### Reducer: kbest   Classifier: knn\n",
      "\n",
      "Best parameters\n",
      "\tclf_knn__n_neighbors: 8\n",
      "\tred_kbest__k: 5\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: None\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9082466567607727\n",
      "\n",
      "Step 0 Reducer kbest Classifier dtree\n",
      "### Reducer: kbest   Classifier: dtree\n",
      "\n",
      "Best parameters\n",
      "\tred_kbest__k: 5\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.2\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: None\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9026745913818722\n",
      "\n",
      "Step 0 Reducer kbest Classifier nb\n",
      "### Reducer: kbest   Classifier: nb\n",
      "\n",
      "Best parameters\n",
      "\tred_kbest__k: 5\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: None\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.8462109955423477\n",
      "\n",
      "Step 0 Reducer kbest Classifier lr\n",
      "### Reducer: kbest   Classifier: lr\n",
      "\n",
      "Best parameters\n",
      "\tred_kbest__k: 5\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: None\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9086181277860327\n",
      "\n",
      "Step 0 Reducer kbest Classifier svc\n",
      "### Reducer: kbest   Classifier: svc\n",
      "\n",
      "Best parameters\n",
      "\tred_kbest__k: 5\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: None\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9115898959881129\n",
      "\n",
      "Step 0 Reducer kbest Classifier lsvc\n",
      "### Reducer: kbest   Classifier: lsvc\n",
      "\n",
      "Best parameters\n",
      "\tred_kbest__k: 5\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.2\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.899702823179792\n",
      "\n",
      "Step 0 Reducer percentile Classifier knn\n",
      "### Reducer: percentile   Classifier: knn\n",
      "\n",
      "Best parameters\n",
      "\tclf_knn__n_neighbors: 8\n",
      "\tred_percentile__percentile: 10\n",
      "\tred_percentile__score_func: <function f_classif at 0x1a1db441e0>\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.936849925705795\n",
      "\n",
      "Step 0 Reducer percentile Classifier dtree\n",
      "### Reducer: percentile   Classifier: dtree\n",
      "\n",
      "Best parameters\n",
      "\tred_percentile__percentile: 10\n",
      "\tred_percentile__score_func: <function f_classif at 0x1a1db441e0>\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: 'english'\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.913447251114413\n",
      "\n",
      "Step 0 Reducer percentile Classifier nb\n",
      "### Reducer: percentile   Classifier: nb\n"
     ]
    }
   ],
   "source": [
    "# First we adjust the vectorizer parameters\n",
    "param_grid_vectorizer = { \n",
    "    'vect__norm': ['l1', 'l2', None],\n",
    "    'vect__max_features': [500, 1000],\n",
    "    'vect__min_df': [0.0, 0.1, 0.2],\n",
    "    'vect__max_df': [0.1, 0.2, 0.5, 1.],\n",
    "    'vect__stop_words': [None, 'english', eng_and_custom_stopwords]\n",
    "}\n",
    "\n",
    "# Then we adjust the reducer parameters\n",
    "param_grid_reducers = [\n",
    "    {\n",
    "         'red_svd__n_components' : [2, 3, 10, 30, 40, 100],\n",
    "         'red_kbest__k' : [5, 8, 10],\n",
    "         'red_percentile__score_func' : [f_classif],\n",
    "         'red_percentile__percentile' : [5, 10]\n",
    "    }\n",
    "]\n",
    "\n",
    "param_grid_classifiers = {\n",
    "    'clf_knn__n_neighbors' : [2, 5, 8, 10, 12, 24]\n",
    "}\n",
    "\n",
    "df_metrics_all = hyper_grid_search([param_grid_vectorizer, param_grid_reducers, param_grid_classifiers], \n",
    "                                   df_metrics_fixed, reducers=reducers, classifiers=classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reducer</th>\n",
       "      <th>classifier</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>33</td>\n",
       "      <td>{'red_svd__n_components': 10, 'scaler': None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>33</td>\n",
       "      <td>{'clf_knn__n_neighbors': 8, 'red_svd__n_compon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>33</td>\n",
       "      <td>{'red_svd__n_components': 10, 'scaler': None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kbest</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>33</td>\n",
       "      <td>{'red_kbest__k': 3, 'scaler': None, 'vect__ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kbest</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'clf_knn__n_neighbors': 8, 'red_kbest__k': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kbest</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>33</td>\n",
       "      <td>{'red_kbest__k': 3, 'scaler': None, 'vect__ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svd</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kbest</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svd</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kbest</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svd</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kbest</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reducer classifier  precision    recall  f1-score  support  \\\n",
       "0     svd       lsvc   0.969697  0.969697  0.969697       33   \n",
       "0     svd        knn   0.969697  0.969697  0.969697       33   \n",
       "0     svd         lr   0.969697  0.969697  0.969697       33   \n",
       "0   kbest       lsvc   0.818182  0.818182  0.818182       33   \n",
       "0   kbest        knn   0.939394  0.939394  0.939394       33   \n",
       "0   kbest         lr   0.848485  0.848485  0.848485       33   \n",
       "2     svd      dtree   0.939394  0.939394  0.939394       33   \n",
       "3   kbest      dtree   0.878788  0.878788  0.878788       33   \n",
       "4     svd         nb   0.909091  0.909091  0.909091       33   \n",
       "5   kbest         nb   0.575758  0.575758  0.575758       33   \n",
       "8     svd        svc   0.454545  0.454545  0.454545       33   \n",
       "9   kbest        svc   0.454545  0.454545  0.454545       33   \n",
       "\n",
       "                                              params  \n",
       "0  {'red_svd__n_components': 10, 'scaler': None, ...  \n",
       "0  {'clf_knn__n_neighbors': 8, 'red_svd__n_compon...  \n",
       "0  {'red_svd__n_components': 10, 'scaler': None, ...  \n",
       "0  {'red_kbest__k': 3, 'scaler': None, 'vect__ana...  \n",
       "0  {'clf_knn__n_neighbors': 8, 'red_kbest__k': 3,...  \n",
       "0  {'red_kbest__k': 3, 'scaler': None, 'vect__ana...  \n",
       "2  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "3  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "4  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "5  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "8  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "9  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reducer</th>\n",
       "      <th>classifier</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kbest</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svd</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kbest</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svd</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kbest</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svd</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kbest</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svd</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kbest</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>svd</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kbest</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>33</td>\n",
       "      <td>{'vect__norm': 'l2', 'vect__smooth_idf': True,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reducer classifier  precision    recall  f1-score  support  \\\n",
       "0      svd        knn   0.969697  0.969697  0.969697       33   \n",
       "1    kbest        knn   0.939394  0.939394  0.939394       33   \n",
       "2      svd      dtree   0.939394  0.939394  0.939394       33   \n",
       "3    kbest      dtree   0.878788  0.878788  0.878788       33   \n",
       "4      svd         nb   0.909091  0.909091  0.909091       33   \n",
       "5    kbest         nb   0.575758  0.575758  0.575758       33   \n",
       "6      svd         lr   0.939394  0.939394  0.939394       33   \n",
       "7    kbest         lr   0.696970  0.696970  0.696970       33   \n",
       "8      svd        svc   0.454545  0.454545  0.454545       33   \n",
       "9    kbest        svc   0.454545  0.454545  0.454545       33   \n",
       "10     svd       lsvc   0.939394  0.939394  0.939394       33   \n",
       "11   kbest       lsvc   0.818182  0.818182  0.818182       33   \n",
       "\n",
       "                                               params  \n",
       "0   {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "1   {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "2   {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "3   {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "4   {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "5   {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "6   {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "7   {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "8   {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "9   {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "10  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  \n",
       "11  {'vect__norm': 'l2', 'vect__smooth_idf': True,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_metrics_new)\n",
    "display(df_metrics_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_reducers = [\n",
    "    {\n",
    "         'red_svd__n_components' : [2, 3, 10, 30, 40, 100],\n",
    "         'red_kbest__k' : [20, 50, 60],\n",
    "         'red_percentile__score_func' : [f_classif],\n",
    "         'red_percentile__percentile' : [5, 10]\n",
    "    },\n",
    "    {\n",
    "        'red__svd' : ['None']\n",
    "    }\n",
    "]\n",
    "\n",
    "def get_filtered_set(parameters, pipeline):\n",
    "    \"\"\" Filter the params that aren't related to steps in the pipeline \"\"\"\n",
    "    if type(parameters) == dict:\n",
    "        return get_filtered_params(parameters, pipeline)\n",
    "    else:\n",
    "        filtered_set = []\n",
    "        for param_set in parameters:\n",
    "            filtered_set.append(get_filtered_params(param_set, pipeline))\n",
    "        return filtered_set\n",
    "\n",
    "def is_reducer_affected(parameters, reducer):\n",
    "    \"\"\" Filter the params that aren't related to steps in the pipeline \"\"\"\n",
    "    filtered_params = {}\n",
    "    for param_key in parameters.keys():\n",
    "        if param_key.split('__')[0] in pipeline.named_steps.keys():\n",
    "            filtered_params[param_key] = parameters[param_key]\n",
    "    return filtered_params\n",
    "\n",
    "def params2affected(parameters_search):\n",
    "    \"\"\" Convert params to search params \"\"\"\n",
    "    # Generalize params to list of params\n",
    "    if type(parameters_search) == dict:\n",
    "        parameters = [parameters_search]\n",
    "    else:\n",
    "        parameters = parameters_search\n",
    "    reducers = []\n",
    "    classifiers = []\n",
    "    for param_set in parameters:\n",
    "        for param_key in param_set.keys():\n",
    "            key = param_key.split('__')[0]\n",
    "            t, name = key.split('_')\n",
    "            if t == 'red'\n",
    "                reducers.append[name]\n",
    "            else:\n",
    "                classifiers.append[name]\n",
    "        search_params_set.append(search_params)\n",
    "    return reducers, classifiers\n",
    "\n",
    "reducers, classifiers = params2affected(param_grid_reducers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Construction of a clustering of biology documents\n",
    "We already know the class information in our dataset (positive and negative) but we will test if an automatic clustering system discovers automatically these classes (“labels”). The objective is to learn strategies that will be very useful when we have to cluster unlabeled documents. Therefore, we “hide” this information (the real class) to the clustering algorithm. \n",
    "\n",
    "The objective in this section is to check what are the parameters that maximize clustering’s quality. The parameters to be taken into account are:\n",
    "\n",
    "- In function TfidfVectorizer:\n",
    "\n",
    "    * Vocabulary (larger or smaller)\n",
    "    * Norm (none, ‘l1’ or ‘l2’)\n",
    "    \n",
    "- In Latent Semantic Analysis (LSA):\n",
    "\n",
    "    * n_components\n",
    "    * o not performing LSA\n",
    "    \n",
    "- Normalize the data/not normalize it with “Normalizer” (included in the notebook).\n",
    "\n",
    "The questions to be responded in this part are:\n",
    "\n",
    "- Which tips can you give about constructing a text clustering with k-means? What do you recommend to do? What do you recommend not to do?\n",
    "\n",
    "- What is the best clustering you have obtained? The quality of the cluster is the degree of correspondence between real class and assigned cluster. For example:\n",
    "\n",
    "    * If there are 2 clusters and cluster 0 contains all examples of positive class and cluster 1 contains all examples of negative class, the clustering is perfect.\n",
    "    * If there are 2 clusters and cluster 1 contains all examples of positive class and cluster 0 contains all examples of negative class, the clustering is also perfect.\n",
    "    *  If there are 2 clusters and cluster 0 contains 50% of examples of positive class and 50% of examples of negative class, and statistics in cluster 1 are similar, the clustering quality is the worst possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy (tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main process with prefixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Reducer: svd   Classifier: kmeans\n",
      "Accuracy 0.9361069836552749\n",
      "\n",
      "### Reducer: kbest   Classifier: kmeans\n",
      "Accuracy 0.7964338781575037\n",
      "\n",
      "### Reducer: percentile   Classifier: kmeans\n",
      "Accuracy 0.9294205052005944\n",
      "\n",
      "### Reducer: none   Classifier: kmeans\n",
      "Accuracy 0.9528231797919762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_ini = { \n",
    "    'vect__smooth_idf': True,\n",
    "    'vect__sublinear_tf': True,\n",
    "    'vect__max_features': 1000,\n",
    "    'vect__min_df': 1,\n",
    "    'vect__max_df': 1.,\n",
    "    'vect__stop_words': 'english',\n",
    "    'vect__strip_accents' : 'unicode',\n",
    "    'vect__analyzer' : 'word',\n",
    "    'vect__ngram_range' : (1, 2),\n",
    "    'vect__norm': 'l2',\n",
    "    'red_svd__n_components': 10,\n",
    "    'clf_knn__n_neighbors' : 2,\n",
    "    'clf_kmeans__n_clusters' : 2,\n",
    "    'red_kbest__k' : 3,\n",
    "    'red_percentile__score_func' : f_classif,\n",
    "    'red_percentile__percentile' : 10,\n",
    "    'scaler': None\n",
    "    #'scaler__with_mean' : False\n",
    "}\n",
    "\n",
    "reducers=REDUCERS\n",
    "classifiers=['kmeans']\n",
    "df_metrics_fixed_kmeans = process_classifications(X_train, y_train, X_test, y_test, param_ini, \n",
    "                             reducers=reducers, classifiers=classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reducer</th>\n",
       "      <th>classifier</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.936107</td>\n",
       "      <td>0.936107</td>\n",
       "      <td>0.936107</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__smooth_idf': True, 'vect__sublinear_tf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kbest</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.796434</td>\n",
       "      <td>0.796434</td>\n",
       "      <td>0.796434</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__smooth_idf': True, 'vect__sublinear_tf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>percentile</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.929421</td>\n",
       "      <td>0.929421</td>\n",
       "      <td>0.929421</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__smooth_idf': True, 'vect__sublinear_tf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.952823</td>\n",
       "      <td>0.952823</td>\n",
       "      <td>0.952823</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'vect__smooth_idf': True, 'vect__sublinear_tf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reducer classifier  precision    recall  f1-score  support  \\\n",
       "0         svd     kmeans   0.936107  0.936107  0.936107     2692   \n",
       "1       kbest     kmeans   0.796434  0.796434  0.796434     2692   \n",
       "2  percentile     kmeans   0.929421  0.929421  0.929421     2692   \n",
       "3        none     kmeans   0.952823  0.952823  0.952823     2692   \n",
       "\n",
       "                                              params  \n",
       "0  {'vect__smooth_idf': True, 'vect__sublinear_tf...  \n",
       "1  {'vect__smooth_idf': True, 'vect__sublinear_tf...  \n",
       "2  {'vect__smooth_idf': True, 'vect__sublinear_tf...  \n",
       "3  {'vect__smooth_idf': True, 'vect__sublinear_tf...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_metrics_fixed_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main process with grid search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words count: 449\n",
      "Step 0 Reducer svd Classifier kmeans\n",
      "### Reducer: svd   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tred_svd__n_components: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9446508172362555\n",
      "\n",
      "Step 0 Reducer kbest Classifier kmeans\n",
      "### Reducer: kbest   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tred_kbest__k: 3\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: {'observed', 'what', 'first', 'reduced', 'con', 'disease', 'respectively', 'domain', 'where', 'all', 'seemed', 'wherein', 'front', 'seem', 'in', 'without', 'myself', 'while', 'her', 'related', 'acid', 'using', 'mill', 'here', 'type', 'twenty', 'already', 'may', 'when', 'will', 'response', 'until', 'transcription', 'mutant', 'development', 'moreover', 'effects', 'pathway', 'seems', 'everyone', 'can', 'every', 'around', 'other', 'factors', 'ever', 'per', 'show', 'on', 'none', 'couldnt', 'report', 'sometime', 'anyhow', 'throughout', 'again', 'upon', 'seeming', 'proteins', 'de', 'go', 'eight', 'nine', 'new', 'provide', '95', 'take', 'regulation', 'cant', 'human', 'results', 'herein', 'three', 'done', 'factor', 'once', 'much', 'membrane', 'him', 'associated', 'gene', 'sincere', 'hers', 'both', 'find', 'everything', 'between', 'like', 'put', 'should', 'function', 'five', 'system', 'us', 'growth', 'cancer', 'herself', 'be', 'data', 'with', 'there', 'for', 'been', 'effect', '10', 'cellular', 'degradation', 'me', 'functions', 'very', 'vivo', 'analysis', 'cell', 'whose', 'keep', 'are', 'because', 'the', 'would', 'call', 'still', 'time', 'thence', 'levels', 'mostly', 'bill', 'off', 'domains', 'anything', 'his', 'interest', 'of', 'always', 'target', 'among', 'compared', 'four', 'might', 'expression', 'involved', 'anyway', 'addition', 'becoming', 'protein', 'association', 'after', 'became', 'before', 'structure', 'by', 'eg', 'stress', 'furthermore', 'at', 'behind', 'eleven', 'someone', 'treatment', 'yourself', 'ten', 'whither', 'becomes', 'to', 'made', 'role', 'ourselves', 'being', 'along', 'clinical', 'via', 'two', 'studies', 'interacts', 'she', 'either', 'identified', 'above', 'towards', 'formation', 'family', 'third', 'tumor', 'under', 'genes', 'beforehand', 'itself', 'who', 'cells', 'interactions', 'nuclear', 'mine', 'interaction', 'anyone', 'we', 'significant', 'vitro', 'must', 'higher', 'signaling', 'our', 'suggest', 'except', 'phosphorylation', 'study', 'hereby', 'whereby', 'next', 'binding', 'non', 'beside', 'mutations', 'nothing', 're', 'since', 'empty', 'do', 'due', 'whatever', 'risk', 'residues', 'form', 'neither', 'full', 'often', 'has', 'fill', 'perhaps', 'group', 'different', 'latterly', 'low', 'molecular', 'serious', 'few', 'whereafter', 'essential', 'high', 'than', 'whence', 'them', 'thus', 'an', 'less', 'you', 'bottom', 'demonstrated', 'namely', 'everywhere', 'nevertheless', 'its', 'others', 'patients', 'activity', 'detail', 'themselves', 'methods', 'required', 'himself', 'own', 'noone', 'alpha', 'yours', 'whether', 'over', 'now', 'used', 'as', 'terminal', 'but', 'least', 'some', 'describe', 'potential', 'below', 'a', 'formerly', 'not', 'your', 'nor', 'use', 'no', 'nobody', 'meanwhile', 'part', 'across', 'hundred', 'binds', 'former', 'my', 'move', 'down', 'indeed', 'was', 'whereupon', 'back', 'most', 'p53', 'complex', 'too', 'also', 'or', 'un', 'never', 'co', 'activation', 'how', 'see', 'from', 'fire', 'enough', 'which', 'whereas', 'amongst', 'several', 'out', 'though', 'give', 'besides', 'more', 'ie', 'something', 'am', 'cry', 'ltd', 'only', 'amount', 'they', 'afterwards', 'whom', 'mediated', 'such', 'into', 'thereupon', 'whenever', 'why', 'dependent', 'although', 'based', 'side', 'then', 'hence', 'site', 'beta', 'surface', 'amoungst', 'could', 'further', 'up', 'dna', 'novel', 'whoever', 'increased', 'fifteen', 'six', 'wherever', 'elsewhere', 'this', 'their', 'thereby', 'yet', 'same', 'significantly', 'sometimes', 'have', 'kinase', 'i', 'anywhere', 'together', 'mechanism', 'if', 'mutation', 'findings', 'that', 'receptor', 'revealed', 'against', 'model', 'toward', 'therefore', 'including', 'name', 'had', 'almost', '14', 'forty', 'those', 'important', 'even', 'fifty', 'ours', 'top', 'present', 'sixty', 'during', 'etc', 'inc', 'any', 'another', 'each', 'thru', 'whole', 'many', 'however', 'hereafter', 'twelve', 'functional', 'please', 'and', 'control', 'thick', 'onto', 'thereafter', 'demonstrate', 'hereupon', 'one', 'known', 'latter', 'so', 'yourselves', 'hasnt', 'therein', 'nowhere', 'well', 'become', 'cannot', 'within', 'somewhere', 'motif', 'is', 'found', 'about', 'rather', 'these', 'through', 'somehow', 'thin', 'showed', 'else', 'he', 'last', 'otherwise', 'get', 'were', 'region', 'induced', 'beyond', 'it', 'alone', 'specific'}\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.5776374442793462\n",
      "\n",
      "Step 0 Reducer percentile Classifier kmeans\n",
      "### Reducer: percentile   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tred_percentile__percentile: 10\n",
      "\tred_percentile__score_func: <function f_classif at 0x1a1db441e0>\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9446508172362555\n",
      "\n",
      "Step 0 Reducer none Classifier kmeans\n",
      "### Reducer: none   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9439078751857355\n",
      "\n",
      "Step 1 Reducer svd Classifier kmeans\n",
      "### Reducer: svd   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tred_svd__n_components: 2\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9353640416047548\n",
      "\n",
      "Step 1 Reducer kbest Classifier kmeans\n",
      "### Reducer: kbest   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tred_kbest__k: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: {'observed', 'what', 'first', 'reduced', 'con', 'disease', 'respectively', 'domain', 'where', 'all', 'seemed', 'wherein', 'front', 'seem', 'in', 'without', 'myself', 'while', 'her', 'related', 'acid', 'using', 'mill', 'here', 'type', 'twenty', 'already', 'may', 'when', 'will', 'response', 'until', 'transcription', 'mutant', 'development', 'moreover', 'effects', 'pathway', 'seems', 'everyone', 'can', 'every', 'around', 'other', 'factors', 'ever', 'per', 'show', 'on', 'none', 'couldnt', 'report', 'sometime', 'anyhow', 'throughout', 'again', 'upon', 'seeming', 'proteins', 'de', 'go', 'eight', 'nine', 'new', 'provide', '95', 'take', 'regulation', 'cant', 'human', 'results', 'herein', 'three', 'done', 'factor', 'once', 'much', 'membrane', 'him', 'associated', 'gene', 'sincere', 'hers', 'both', 'find', 'everything', 'between', 'like', 'put', 'should', 'function', 'five', 'system', 'us', 'growth', 'cancer', 'herself', 'be', 'data', 'with', 'there', 'for', 'been', 'effect', '10', 'cellular', 'degradation', 'me', 'functions', 'very', 'vivo', 'analysis', 'cell', 'whose', 'keep', 'are', 'because', 'the', 'would', 'call', 'still', 'time', 'thence', 'levels', 'mostly', 'bill', 'off', 'domains', 'anything', 'his', 'interest', 'of', 'always', 'target', 'among', 'compared', 'four', 'might', 'expression', 'involved', 'anyway', 'addition', 'becoming', 'protein', 'association', 'after', 'became', 'before', 'structure', 'by', 'eg', 'stress', 'furthermore', 'at', 'behind', 'eleven', 'someone', 'treatment', 'yourself', 'ten', 'whither', 'becomes', 'to', 'made', 'role', 'ourselves', 'being', 'along', 'clinical', 'via', 'two', 'studies', 'interacts', 'she', 'either', 'identified', 'above', 'towards', 'formation', 'family', 'third', 'tumor', 'under', 'genes', 'beforehand', 'itself', 'who', 'cells', 'interactions', 'nuclear', 'mine', 'interaction', 'anyone', 'we', 'significant', 'vitro', 'must', 'higher', 'signaling', 'our', 'suggest', 'except', 'phosphorylation', 'study', 'hereby', 'whereby', 'next', 'binding', 'non', 'beside', 'mutations', 'nothing', 're', 'since', 'empty', 'do', 'due', 'whatever', 'risk', 'residues', 'form', 'neither', 'full', 'often', 'has', 'fill', 'perhaps', 'group', 'different', 'latterly', 'low', 'molecular', 'serious', 'few', 'whereafter', 'essential', 'high', 'than', 'whence', 'them', 'thus', 'an', 'less', 'you', 'bottom', 'demonstrated', 'namely', 'everywhere', 'nevertheless', 'its', 'others', 'patients', 'activity', 'detail', 'themselves', 'methods', 'required', 'himself', 'own', 'noone', 'alpha', 'yours', 'whether', 'over', 'now', 'used', 'as', 'terminal', 'but', 'least', 'some', 'describe', 'potential', 'below', 'a', 'formerly', 'not', 'your', 'nor', 'use', 'no', 'nobody', 'meanwhile', 'part', 'across', 'hundred', 'binds', 'former', 'my', 'move', 'down', 'indeed', 'was', 'whereupon', 'back', 'most', 'p53', 'complex', 'too', 'also', 'or', 'un', 'never', 'co', 'activation', 'how', 'see', 'from', 'fire', 'enough', 'which', 'whereas', 'amongst', 'several', 'out', 'though', 'give', 'besides', 'more', 'ie', 'something', 'am', 'cry', 'ltd', 'only', 'amount', 'they', 'afterwards', 'whom', 'mediated', 'such', 'into', 'thereupon', 'whenever', 'why', 'dependent', 'although', 'based', 'side', 'then', 'hence', 'site', 'beta', 'surface', 'amoungst', 'could', 'further', 'up', 'dna', 'novel', 'whoever', 'increased', 'fifteen', 'six', 'wherever', 'elsewhere', 'this', 'their', 'thereby', 'yet', 'same', 'significantly', 'sometimes', 'have', 'kinase', 'i', 'anywhere', 'together', 'mechanism', 'if', 'mutation', 'findings', 'that', 'receptor', 'revealed', 'against', 'model', 'toward', 'therefore', 'including', 'name', 'had', 'almost', '14', 'forty', 'those', 'important', 'even', 'fifty', 'ours', 'top', 'present', 'sixty', 'during', 'etc', 'inc', 'any', 'another', 'each', 'thru', 'whole', 'many', 'however', 'hereafter', 'twelve', 'functional', 'please', 'and', 'control', 'thick', 'onto', 'thereafter', 'demonstrate', 'hereupon', 'one', 'known', 'latter', 'so', 'yourselves', 'hasnt', 'therein', 'nowhere', 'well', 'become', 'cannot', 'within', 'somewhere', 'motif', 'is', 'found', 'about', 'rather', 'these', 'through', 'somehow', 'thin', 'showed', 'else', 'he', 'last', 'otherwise', 'get', 'were', 'region', 'induced', 'beyond', 'it', 'alone', 'specific'}\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy 0.5806092124814265\n",
      "\n",
      "Step 1 Reducer percentile Classifier kmeans\n",
      "### Reducer: percentile   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tred_percentile__percentile: 10\n",
      "\tred_percentile__score_func: <function f_classif at 0x1a1db441e0>\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9446508172362555\n",
      "\n",
      "Step 1 Reducer none Classifier kmeans\n",
      "not affected\n",
      "Step 2 Reducer svd Classifier kmeans\n",
      "### Reducer: svd   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tclf_kmeans_norm: None\n",
      "\tred_svd__n_components: 2\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9286775631500743\n",
      "\n",
      "Step 2 Reducer kbest Classifier kmeans\n",
      "### Reducer: kbest   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tclf_kmeans_norm: None\n",
      "\tred_kbest__k: 10\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: {'observed', 'what', 'first', 'reduced', 'con', 'disease', 'respectively', 'domain', 'where', 'all', 'seemed', 'wherein', 'front', 'seem', 'in', 'without', 'myself', 'while', 'her', 'related', 'acid', 'using', 'mill', 'here', 'type', 'twenty', 'already', 'may', 'when', 'will', 'response', 'until', 'transcription', 'mutant', 'development', 'moreover', 'effects', 'pathway', 'seems', 'everyone', 'can', 'every', 'around', 'other', 'factors', 'ever', 'per', 'show', 'on', 'none', 'couldnt', 'report', 'sometime', 'anyhow', 'throughout', 'again', 'upon', 'seeming', 'proteins', 'de', 'go', 'eight', 'nine', 'new', 'provide', '95', 'take', 'regulation', 'cant', 'human', 'results', 'herein', 'three', 'done', 'factor', 'once', 'much', 'membrane', 'him', 'associated', 'gene', 'sincere', 'hers', 'both', 'find', 'everything', 'between', 'like', 'put', 'should', 'function', 'five', 'system', 'us', 'growth', 'cancer', 'herself', 'be', 'data', 'with', 'there', 'for', 'been', 'effect', '10', 'cellular', 'degradation', 'me', 'functions', 'very', 'vivo', 'analysis', 'cell', 'whose', 'keep', 'are', 'because', 'the', 'would', 'call', 'still', 'time', 'thence', 'levels', 'mostly', 'bill', 'off', 'domains', 'anything', 'his', 'interest', 'of', 'always', 'target', 'among', 'compared', 'four', 'might', 'expression', 'involved', 'anyway', 'addition', 'becoming', 'protein', 'association', 'after', 'became', 'before', 'structure', 'by', 'eg', 'stress', 'furthermore', 'at', 'behind', 'eleven', 'someone', 'treatment', 'yourself', 'ten', 'whither', 'becomes', 'to', 'made', 'role', 'ourselves', 'being', 'along', 'clinical', 'via', 'two', 'studies', 'interacts', 'she', 'either', 'identified', 'above', 'towards', 'formation', 'family', 'third', 'tumor', 'under', 'genes', 'beforehand', 'itself', 'who', 'cells', 'interactions', 'nuclear', 'mine', 'interaction', 'anyone', 'we', 'significant', 'vitro', 'must', 'higher', 'signaling', 'our', 'suggest', 'except', 'phosphorylation', 'study', 'hereby', 'whereby', 'next', 'binding', 'non', 'beside', 'mutations', 'nothing', 're', 'since', 'empty', 'do', 'due', 'whatever', 'risk', 'residues', 'form', 'neither', 'full', 'often', 'has', 'fill', 'perhaps', 'group', 'different', 'latterly', 'low', 'molecular', 'serious', 'few', 'whereafter', 'essential', 'high', 'than', 'whence', 'them', 'thus', 'an', 'less', 'you', 'bottom', 'demonstrated', 'namely', 'everywhere', 'nevertheless', 'its', 'others', 'patients', 'activity', 'detail', 'themselves', 'methods', 'required', 'himself', 'own', 'noone', 'alpha', 'yours', 'whether', 'over', 'now', 'used', 'as', 'terminal', 'but', 'least', 'some', 'describe', 'potential', 'below', 'a', 'formerly', 'not', 'your', 'nor', 'use', 'no', 'nobody', 'meanwhile', 'part', 'across', 'hundred', 'binds', 'former', 'my', 'move', 'down', 'indeed', 'was', 'whereupon', 'back', 'most', 'p53', 'complex', 'too', 'also', 'or', 'un', 'never', 'co', 'activation', 'how', 'see', 'from', 'fire', 'enough', 'which', 'whereas', 'amongst', 'several', 'out', 'though', 'give', 'besides', 'more', 'ie', 'something', 'am', 'cry', 'ltd', 'only', 'amount', 'they', 'afterwards', 'whom', 'mediated', 'such', 'into', 'thereupon', 'whenever', 'why', 'dependent', 'although', 'based', 'side', 'then', 'hence', 'site', 'beta', 'surface', 'amoungst', 'could', 'further', 'up', 'dna', 'novel', 'whoever', 'increased', 'fifteen', 'six', 'wherever', 'elsewhere', 'this', 'their', 'thereby', 'yet', 'same', 'significantly', 'sometimes', 'have', 'kinase', 'i', 'anywhere', 'together', 'mechanism', 'if', 'mutation', 'findings', 'that', 'receptor', 'revealed', 'against', 'model', 'toward', 'therefore', 'including', 'name', 'had', 'almost', '14', 'forty', 'those', 'important', 'even', 'fifty', 'ours', 'top', 'present', 'sixty', 'during', 'etc', 'inc', 'any', 'another', 'each', 'thru', 'whole', 'many', 'however', 'hereafter', 'twelve', 'functional', 'please', 'and', 'control', 'thick', 'onto', 'thereafter', 'demonstrate', 'hereupon', 'one', 'known', 'latter', 'so', 'yourselves', 'hasnt', 'therein', 'nowhere', 'well', 'become', 'cannot', 'within', 'somewhere', 'motif', 'is', 'found', 'about', 'rather', 'these', 'through', 'somehow', 'thin', 'showed', 'else', 'he', 'last', 'otherwise', 'get', 'were', 'region', 'induced', 'beyond', 'it', 'alone', 'specific'}\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.674962852897474\n",
      "\n",
      "Step 2 Reducer percentile Classifier kmeans\n",
      "### Reducer: percentile   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tclf_kmeans_norm: None\n",
      "\tred_percentile__percentile: 10\n",
      "\tred_percentile__score_func: <function f_classif at 0x1a1db441e0>\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9431649331352154\n",
      "\n",
      "Step 2 Reducer none Classifier kmeans\n",
      "### Reducer: none   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tclf_kmeans_norm: None\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.9390787518573551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eng_and_custom_stopwords = improve_stop_words(X_train, 200)\n",
    "# First we adjust the vectorizer parameters\n",
    "param_grid_vectorizer = { \n",
    "    'vect__norm': ['l1', 'l2', None],\n",
    "    'vect__max_features': [500, 1000],\n",
    "    'vect__min_df': [0.0],\n",
    "    'vect__max_df': [1.],\n",
    "    'vect__stop_words': [None, 'english', eng_and_custom_stopwords]\n",
    "}\n",
    "\n",
    "# Then we adjust the reducer parameters\n",
    "param_grid_reducers = [\n",
    "    {\n",
    "         'red_svd__n_components' : [2, 3, 10, 30, 40, 100],\n",
    "         'red_kbest__k' : [10, 20, 50],\n",
    "         'red_percentile__score_func' : [f_classif],\n",
    "         'red_percentile__percentile' : [5, 10]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Then we adjust the classifier parameters\n",
    "param_grid_classifiers = [{\n",
    "        'clf_kmeans__n_clusters' : [2]\n",
    "    },\n",
    "    {\n",
    "        'clf_kmeans_norm': [None]\n",
    "    }\n",
    "]\n",
    "\n",
    "df_metrics_all_kmeans = hyper_grid_search([param_grid_vectorizer, param_grid_reducers, param_grid_classifiers], \n",
    "                                   df_metrics_fixed_kmeans, reducers=reducers, classifiers=classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reducer</th>\n",
       "      <th>classifier</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.928678</td>\n",
       "      <td>0.928678</td>\n",
       "      <td>0.928678</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kbest</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.674963</td>\n",
       "      <td>0.674963</td>\n",
       "      <td>0.674963</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>percentile</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.943165</td>\n",
       "      <td>0.943165</td>\n",
       "      <td>0.943165</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.939079</td>\n",
       "      <td>0.939079</td>\n",
       "      <td>0.939079</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reducer classifier  precision    recall  f1-score  support  \\\n",
       "0         svd     kmeans   0.928678  0.928678  0.928678     2692   \n",
       "0       kbest     kmeans   0.674963  0.674963  0.674963     2692   \n",
       "0  percentile     kmeans   0.943165  0.943165  0.943165     2692   \n",
       "0        none     kmeans   0.939079  0.939079  0.939079     2692   \n",
       "\n",
       "                                              params  \n",
       "0  {'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...  \n",
       "0  {'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...  \n",
       "0  {'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...  \n",
       "0  {'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_metrics_all_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 Reducer svd Classifier kmeans\n",
      "not affected\n",
      "Step 0 Reducer kbest Classifier kmeans\n",
      "### Reducer: kbest   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tclf_kmeans_norm: None\n",
      "\tred_kbest__k: 3\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: {'observed', 'what', 'first', 'reduced', 'con', 'disease', 'respectively', 'domain', 'where', 'all', 'seemed', 'wherein', 'front', 'seem', 'in', 'without', 'myself', 'while', 'her', 'related', 'acid', 'using', 'mill', 'here', 'type', 'twenty', 'already', 'may', 'when', 'will', 'response', 'until', 'transcription', 'mutant', 'development', 'moreover', 'effects', 'pathway', 'seems', 'everyone', 'can', 'every', 'around', 'other', 'factors', 'ever', 'per', 'show', 'on', 'none', 'couldnt', 'report', 'sometime', 'anyhow', 'throughout', 'again', 'upon', 'seeming', 'proteins', 'de', 'go', 'eight', 'nine', 'new', 'provide', '95', 'take', 'regulation', 'cant', 'human', 'results', 'herein', 'three', 'done', 'factor', 'once', 'much', 'membrane', 'him', 'associated', 'gene', 'sincere', 'hers', 'both', 'find', 'everything', 'between', 'like', 'put', 'should', 'function', 'five', 'system', 'us', 'growth', 'cancer', 'herself', 'be', 'data', 'with', 'there', 'for', 'been', 'effect', '10', 'cellular', 'degradation', 'me', 'functions', 'very', 'vivo', 'analysis', 'cell', 'whose', 'keep', 'are', 'because', 'the', 'would', 'call', 'still', 'time', 'thence', 'levels', 'mostly', 'bill', 'off', 'domains', 'anything', 'his', 'interest', 'of', 'always', 'target', 'among', 'compared', 'four', 'might', 'expression', 'involved', 'anyway', 'addition', 'becoming', 'protein', 'association', 'after', 'became', 'before', 'structure', 'by', 'eg', 'stress', 'furthermore', 'at', 'behind', 'eleven', 'someone', 'treatment', 'yourself', 'ten', 'whither', 'becomes', 'to', 'made', 'role', 'ourselves', 'being', 'along', 'clinical', 'via', 'two', 'studies', 'interacts', 'she', 'either', 'identified', 'above', 'towards', 'formation', 'family', 'third', 'tumor', 'under', 'genes', 'beforehand', 'itself', 'who', 'cells', 'interactions', 'nuclear', 'mine', 'interaction', 'anyone', 'we', 'significant', 'vitro', 'must', 'higher', 'signaling', 'our', 'suggest', 'except', 'phosphorylation', 'study', 'hereby', 'whereby', 'next', 'binding', 'non', 'beside', 'mutations', 'nothing', 're', 'since', 'empty', 'do', 'due', 'whatever', 'risk', 'residues', 'form', 'neither', 'full', 'often', 'has', 'fill', 'perhaps', 'group', 'different', 'latterly', 'low', 'molecular', 'serious', 'few', 'whereafter', 'essential', 'high', 'than', 'whence', 'them', 'thus', 'an', 'less', 'you', 'bottom', 'demonstrated', 'namely', 'everywhere', 'nevertheless', 'its', 'others', 'patients', 'activity', 'detail', 'themselves', 'methods', 'required', 'himself', 'own', 'noone', 'alpha', 'yours', 'whether', 'over', 'now', 'used', 'as', 'terminal', 'but', 'least', 'some', 'describe', 'potential', 'below', 'a', 'formerly', 'not', 'your', 'nor', 'use', 'no', 'nobody', 'meanwhile', 'part', 'across', 'hundred', 'binds', 'former', 'my', 'move', 'down', 'indeed', 'was', 'whereupon', 'back', 'most', 'p53', 'complex', 'too', 'also', 'or', 'un', 'never', 'co', 'activation', 'how', 'see', 'from', 'fire', 'enough', 'which', 'whereas', 'amongst', 'several', 'out', 'though', 'give', 'besides', 'more', 'ie', 'something', 'am', 'cry', 'ltd', 'only', 'amount', 'they', 'afterwards', 'whom', 'mediated', 'such', 'into', 'thereupon', 'whenever', 'why', 'dependent', 'although', 'based', 'side', 'then', 'hence', 'site', 'beta', 'surface', 'amoungst', 'could', 'further', 'up', 'dna', 'novel', 'whoever', 'increased', 'fifteen', 'six', 'wherever', 'elsewhere', 'this', 'their', 'thereby', 'yet', 'same', 'significantly', 'sometimes', 'have', 'kinase', 'i', 'anywhere', 'together', 'mechanism', 'if', 'mutation', 'findings', 'that', 'receptor', 'revealed', 'against', 'model', 'toward', 'therefore', 'including', 'name', 'had', 'almost', '14', 'forty', 'those', 'important', 'even', 'fifty', 'ours', 'top', 'present', 'sixty', 'during', 'etc', 'inc', 'any', 'another', 'each', 'thru', 'whole', 'many', 'however', 'hereafter', 'twelve', 'functional', 'please', 'and', 'control', 'thick', 'onto', 'thereafter', 'demonstrate', 'hereupon', 'one', 'known', 'latter', 'so', 'yourselves', 'hasnt', 'therein', 'nowhere', 'well', 'become', 'cannot', 'within', 'somewhere', 'motif', 'is', 'found', 'about', 'rather', 'these', 'through', 'somehow', 'thin', 'showed', 'else', 'he', 'last', 'otherwise', 'get', 'were', 'region', 'induced', 'beyond', 'it', 'alone', 'specific'}\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.5702080237741456\n",
      "\n",
      "Step 0 Reducer percentile Classifier kmeans\n",
      "### Reducer: percentile   Classifier: kmeans\n",
      "\n",
      "Best parameters\n",
      "\tclf_kmeans__n_clusters: 2\n",
      "\tclf_kmeans_norm: None\n",
      "\tred_percentile__percentile: 1\n",
      "\tred_percentile__score_func: <function f_classif at 0x1a1db441e0>\n",
      "\tscaler: None\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__max_features: 500\n",
      "\tvect__min_df: 0.0\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__smooth_idf: True\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: 'unicode'\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Accuracy 0.8469539375928677\n",
      "\n",
      "Step 0 Reducer none Classifier kmeans\n",
      "not affected\n"
     ]
    }
   ],
   "source": [
    "# Improve reducers\n",
    "param_grid_reducers = [\n",
    "    {\n",
    "         'red_kbest__k' : [3, 5, 8, 10],\n",
    "         'red_percentile__score_func' : [f_classif],\n",
    "         'red_percentile__percentile' : [1, 2, 3]\n",
    "    }\n",
    "]\n",
    "\n",
    "df_metrics_all_kmeans_2 = hyper_grid_search([param_grid_reducers], \n",
    "                                   df_metrics_all_kmeans, reducers=reducers, classifiers=classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reducer</th>\n",
       "      <th>classifier</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.928678</td>\n",
       "      <td>0.928678</td>\n",
       "      <td>0.928678</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kbest</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.660475</td>\n",
       "      <td>0.660475</td>\n",
       "      <td>0.660475</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>percentile</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.929049</td>\n",
       "      <td>0.929049</td>\n",
       "      <td>0.929049</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.939079</td>\n",
       "      <td>0.939079</td>\n",
       "      <td>0.939079</td>\n",
       "      <td>2692</td>\n",
       "      <td>{'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reducer classifier  precision    recall  f1-score  support  \\\n",
       "0         svd     kmeans   0.928678  0.928678  0.928678     2692   \n",
       "0       kbest     kmeans   0.660475  0.660475  0.660475     2692   \n",
       "0  percentile     kmeans   0.929049  0.929049  0.929049     2692   \n",
       "0        none     kmeans   0.939079  0.939079  0.939079     2692   \n",
       "\n",
       "                                              params  \n",
       "0  {'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...  \n",
       "0  {'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...  \n",
       "0  {'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...  \n",
       "0  {'clf_kmeans__n_clusters': 2, 'clf_kmeans_norm...  "
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_all_kmeans_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "copy = \"1\"\n",
    "binary_file = open('df_metrics_fixed_' + copy + '.bin',mode='wb')\n",
    "pickle.dump(df_metrics_fixed, binary_file)\n",
    "binary_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 1000)\n",
      "Evaluando k=1\n",
      "Evaluando k=2\n",
      "Evaluando k=3\n",
      "Evaluando k=4\n",
      "Evaluando k=5\n",
      "Evaluando k=6\n",
      "Evaluando k=7\n",
      "Evaluando k=8\n",
      "Evaluando k=9\n",
      "Evaluando k=10\n",
      "Evaluando k=11\n",
      "Evaluando k=12\n",
      "Evaluando k=13\n",
      "Evaluando k=14\n",
      "Evaluando k=15\n",
      "Evaluando k=16\n",
      "Evaluando k=17\n",
      "Evaluando k=18\n",
      "Evaluando k=19\n",
      "Evaluando k=20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def get_X_transform(X):\n",
    "    vectorizador = TfidfVectorizer(max_df=1., max_features=1000, norm='l2',\n",
    "                                   min_df=1, stop_words='english',\n",
    "                                   #stop_words=stopwords,\n",
    "                                   #token_pattern=r'(?u)\\b[A-Za-z]+\\b',\n",
    "                                   #token_pattern=r'(?ui)\\b\\w*[a-z]+\\w*\\b',\n",
    "                                   use_idf=True)\n",
    "    \n",
    "    vectorizador = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "        encoding='utf-8', input='content',\n",
    "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
    "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
    "        stop_words='english', strip_accents='unicode', sublinear_tf=True,\n",
    "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
    "        vocabulary=None)\n",
    "    \n",
    "    X = vectorizador.fit_transform(X)\n",
    "\n",
    "    print(X.shape)\n",
    "    n_componentes = 100\n",
    "    svd_truncado = TruncatedSVD(n_componentes)\n",
    "    normalizador = Normalizer(copy=False)\n",
    "\n",
    "    lsa = make_pipeline(svd_truncado, normalizador)\n",
    "    #lsa = svd_truncado\n",
    "\n",
    "    X_lsa = lsa.fit_transform(X)\n",
    "\n",
    "    varianza_explicada = svd_truncado.explained_variance_ratio_.sum()\n",
    "    normalizer = Normalizer()\n",
    "    X_lsa_norm = normalizer.fit_transform(X_lsa)\n",
    "    return X_lsa_norm\n",
    "\n",
    "X_km = get_X_transform(X_train)\n",
    "qmetric = calinski_harabaz_score\n",
    "\n",
    "Nclusters_max = 15\n",
    "Nrepetitions = 100\n",
    "\n",
    "qualities = []\n",
    "inertias = []\n",
    "models = []\n",
    "kini = 1\n",
    "kfin = 20\n",
    "for k in range(kini,kfin+1):\n",
    "    print(\"Evaluando k=%d\" % k)\n",
    "    km = KMeans(n_clusters=k,\n",
    "                init='k-means++', n_init=Nrepetitions,\n",
    "                max_iter=500, random_state=2)    \n",
    "    km.fit(X_km)\n",
    "    models.append(km)\n",
    "    inertias.append(km.inertia_)\n",
    "    if k > 1:\n",
    "        qualities.append(qmetric(X_km, km.labels_))\n",
    "        #qualities.append(km.score(X_km))\n",
    "    else:\n",
    "        qualities.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of clusters 1\n",
      "Number of clusters of best quality 2\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14,3))\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "plt.plot(range(kini,kfin+1), inertias, marker='o')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.title('clustering inertia')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "plt.plot(range(kini,kfin+1), qualities, marker='o')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.title('clustering quality')\n",
    "plt.show()\n",
    "\n",
    "best = pd.Series(qualities).idxmax() # get index for the best model\n",
    "print(\"Best number of clusters\", best)\n",
    "km = models[best]\n",
    "n_clusters = km.get_params()['n_clusters']\n",
    "clusters = km.labels_\n",
    "print ('Number of clusters of best quality', n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 1000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        15\n",
      "           1       0.90      1.00      0.95        18\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        33\n",
      "   macro avg       0.95      0.93      0.94        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n",
      "[[13  2]\n",
      " [ 0 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.13      0.11        15\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "   micro avg       0.06      0.06      0.06        33\n",
      "   macro avg       0.05      0.07      0.06        33\n",
      "weighted avg       0.05      0.06      0.05        33\n",
      "\n",
      "[[ 2 13]\n",
      " [18  0]]\n"
     ]
    }
   ],
   "source": [
    "# We choose the best option to evaluate the quality of prediction\n",
    "X = X_test\n",
    "y = y_test\n",
    "X_km = get_X_transform(X)\n",
    "labels = km.fit_predict(X_km)\n",
    "#print(labels)\n",
    "# First we try with labels as is \n",
    "labels_predicted = [str(label) for label in labels]\n",
    "predicted = pd.Series(labels_predicted)\n",
    "#print(labels_predicted)\n",
    "print(metrics.classification_report(y, predicted))\n",
    "print(metrics.confusion_matrix(y, predicted))\n",
    "\n",
    "# Alternatively we invert the label to match the real labels of each group\n",
    "labels_predicted = [str((label + 1)%2) for label in labels]\n",
    "#print(labels_predicted)\n",
    "predicted = pd.Series(labels_predicted)\n",
    "print(metrics.classification_report(y, predicted))\n",
    "print(metrics.confusion_matrix(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4,    5,    6,    7,    8,    9,   11,   13,   15,   17,   20,\n",
       "         23,   27,   32,   37,   43,   49,   57,   67,   78,   90,  105,\n",
       "        121,  141,  163,  190,  220,  256,  296,  344,  399,  463,  537,\n",
       "        624,  724,  840,  974, 1130, 1311, 1521, 1765, 2048, 2375, 2756,\n",
       "       3197, 3709, 4303, 4993, 5792])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.logspace(2, 12.5, num=50, endpoint=True, base=2.0, dtype=int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "latex_metadata": {
     "hidden": "true",
     "lexer": "bash"
    }
   },
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {
    "latex_metadata": {
     "hidden": "true",
     "lexer": "bash"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "jupyter nbconvert --to=latex --template=~/report.tplx TextMining_Assignment.ipynb 1>/dev/null 2>/dev/null\n",
    "/Library/TeX/texbin/pdflatex -shell-escape TextMining_Assignment 1>/dev/null 2>/dev/null\n",
    "jupyter nbconvert --to html_toc TextMining_Assignment.ipynb 1>/dev/null 2>/dev/null"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "latex_metadata": {
   "author": "Elena Montenegro, Fernando Freire",
   "title": "Text Mining Assignment"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "308.828125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
